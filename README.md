# Deep Learning in 15 days

This repository is designed to help you master the essentials of deep learning in just 15 days. Each day focuses on a specific concept, combining theory, math, and practical coding implementations. Whether you're a beginner or looking to deepen your understanding, this structured approach balances learning and hands-on practice.  

---

## Table of Contents  
- [Project Overview](#project-overview)  
- [Why Deep Learning?](#why-deep-learning)  
- [Technologies Used](#technologies-used)  
- [Roadmap](#roadmap)  
- [Installation](#installation)  
- [How to Use This Repository](#how-to-use-this-repository)  
- [Highlights](#highlights)  
- [Contributing](#contributing)  
- [License](#license)  

---

## Project Overview  
Deep learning is a subset of machine learning, inspired by the structure and function of the human brain. This repository provides a guided journey to understand and implement deep learning concepts, focusing on both theoretical foundations and practical applications.  

The curriculum includes:  
1. **Mathematics for Deep Learning**: Understand the equations and concepts behind neural networks.  
2. **Practical Implementations**: Use Python libraries like NumPy, TensorFlow, and Keras to build and train models.  
3. **Real-World Applications**: Explore use cases like image classification, text generation, and deploying models.  

By the end of 15 days, you’ll have a solid understanding of deep learning, from perceptrons to transformers.  

---

## Why Deep Learning?  
Deep learning powers innovations across industries:  
- **Computer Vision**: Image recognition, object detection, and autonomous vehicles.  
- **Natural Language Processing**: Chatbots, sentiment analysis, and language translation.  
- **Generative Models**: Creating art, music, and realistic images.  

This roadmap equips you with the tools to start contributing to these fields.  

---

## Technologies Used  
- **Programming Language**: Python  
- **Libraries and Frameworks**:  
  - Data Processing: `NumPy`, `pandas`  
  - Deep Learning: `TensorFlow`, `Keras`  
  - Visualization: `matplotlib`, `seaborn`  

---

## Roadmap  
### Day 1: Introduction to Deep Learning  
- **Learn**: Neural networks, layers, weights, and activations.  
- **Implement**: A simple perceptron with NumPy.  

### Day 2: Linear Algebra and Matrices  
- **Learn**: Basics of tensors, matrix operations, and their significance in backpropagation.  
- **Implement**: Tensor operations in NumPy.  

### Day 3: Activation Functions  
- **Learn**: Sigmoid, ReLU, tanh, and softmax functions.  
- **Implement**: Visualize and code activation functions.  

### Day 4: Forward and Backpropagation  
- **Learn**: The chain rule for gradient calculation.  
- **Implement**: Manual forward and backward passes for a simple network.  

### Day 5: Optimization Algorithms  
- **Learn**: Gradient Descent, SGD, Adam, and RMSProp.  
- **Implement**: Write an SGD optimizer from scratch.  

### Day 6: Loss Functions  
- **Learn**: MSE, Cross-Entropy, and their gradients.  
- **Implement**: Compare loss functions on sample data.  

### Day 7: Neural Network Architectures  
- **Learn**: Input, hidden, and output layers; overfitting risks.  
- **Implement**: A simple Keras neural network.  

### Day 8: Regularization Techniques  
- **Learn**: L1/L2 regularization, Dropout, and BatchNorm.  
- **Implement**: Add Dropout to prevent overfitting.  

### Day 9: Convolutional Neural Networks (CNNs)  
- **Learn**: Feature extraction and pooling in images.  
- **Implement**: A CNN for MNIST classification.  

### Day 10: Recurrent Neural Networks (RNNs)  
- **Learn**: Time steps and hidden states.  
- **Implement**: Basic RNN for text generation.  

### Day 11: Long Short-Term Memory (LSTM) and GRU  
- **Learn**: Gates in LSTMs and GRUs.  
- **Implement**: LSTM for sentiment analysis.  

### Day 12: Transfer Learning  
- **Learn**: Fine-tuning pre-trained models like ResNet or BERT.  
- **Implement**: Fine-tune ResNet on a custom dataset.  

### Day 13: Generative Models (GANs and VAEs)  
- **Learn**: Generate data using GANs and VAEs.  
- **Implement**: A GAN for MNIST generation.  

### Day 14: Attention Mechanism and Transformers  
- **Learn**: Scaled dot-product attention and transformer architecture.  
- **Implement**: Use a pre-trained Hugging Face model for NLP tasks.  

### Day 15: Model Deployment  
- **Learn**: Deploy deep learning models with Flask or TensorFlow Serving.  
- **Implement**: Serve a model via a REST API.  

---


## How to Use This Repository  
- Each day has its own folder with:  
  - A **README** summarizing key concepts.  
  - A **Jupyter Notebook** for implementation.  
- Follow the roadmap day by day, ensuring a balance between theory and practice.  

---

## Highlights  
- **Comprehensive**: Covers theory, math, and code for key deep learning concepts.  
- **Hands-On**: Focus on coding to solidify understanding.  
- **Structured Learning**: 15-day roadmap for consistent progress.  

---

## Contributing  
Contributions are welcome! If you’d like to improve or extend this project, please fork the repository and submit a pull request.  

